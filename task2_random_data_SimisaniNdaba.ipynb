{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sndaba/BinaryClassification-with-SVM-inRandPython-/blob/main/task2_random_data_SimisaniNdaba.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2bce52f1-dfbf-4e62-8bb7-feb9fbc153a2",
      "metadata": {
        "id": "2bce52f1-dfbf-4e62-8bb7-feb9fbc153a2"
      },
      "source": [
        "# Task 2: Random Data?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "527419fe-8e73-4bd4-bde5-28cdcc92a861",
      "metadata": {
        "id": "527419fe-8e73-4bd4-bde5-28cdcc92a861"
      },
      "source": [
        "## Question"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ae778c4-8eaa-4b28-91f9-58004a71f914",
      "metadata": {
        "id": "1ae778c4-8eaa-4b28-91f9-58004a71f914"
      },
      "source": [
        "> I ran the following code for a binary classification task w/ an SVM in both R (first sample) and Python (second example).\n",
        ">\n",
        "> Given randomly generated data (X) and response (Y), this code performs leave group out cross validation 1000 times. Each entry of Y is therefore the mean of the prediction across CV iterations.\n",
        ">\n",
        "> Computing area under the curve should give ~0.5, since X and Y are completely random. However, this is not what we see. Area under the curve is frequently significantly higher than 0.5. The number of rows of X is very small, which can obviously cause problems.\n",
        ">\n",
        "> Any idea what could be happening here? I know that I can either increase the number of rows of X or decrease the number of columns to mediate the problem, but I am looking for other issues."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7eecb359-6799-4523-9cdd-05187e1230b2",
      "metadata": {
        "id": "7eecb359-6799-4523-9cdd-05187e1230b2"
      },
      "source": [
        "```R\n",
        "Y=as.factor(rep(c(1,2), times=14))\n",
        "X=matrix(runif(length(Y)*100), nrow=length(Y))\n",
        "\n",
        "library(e1071)\n",
        "library(pROC)\n",
        "\n",
        "colnames(X)=1:ncol(X)\n",
        "iter=1000\n",
        "ansMat=matrix(NA,length(Y),iter)\n",
        "for(i in seq(iter)){\n",
        "    #get train\n",
        "\n",
        "    train=sample(seq(length(Y)),0.5*length(Y))\n",
        "    if(min(table(Y[train]))==0)\n",
        "    next\n",
        "\n",
        "    #test from train\n",
        "    test=seq(length(Y))[-train]\n",
        "\n",
        "    #train model\n",
        "    XX=X[train,]\n",
        "    YY=Y[train]\n",
        "    mod=svm(XX,YY,probability=FALSE)\n",
        "    XXX=X[test,]\n",
        "    predVec=predict(mod,XXX)\n",
        "    RFans=attr(predVec,'decision.values')\n",
        "    ansMat[test,i]=as.numeric(predVec)\n",
        "}\n",
        "\n",
        "ans=rowMeans(ansMat,na.rm=TRUE)\n",
        "\n",
        "r=roc(Y,ans)$auc\n",
        "print(r)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d14e4617-608b-4749-9ec5-edf15814f5bf",
      "metadata": {
        "id": "d14e4617-608b-4749-9ec5-edf15814f5bf"
      },
      "source": [
        "Similarly, when I implement the same thing in Python I get similar results.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0cf44d8d-ca36-4d6b-bafd-78cade069751",
      "metadata": {
        "id": "0cf44d8d-ca36-4d6b-bafd-78cade069751",
        "outputId": "c92a7a9e-c4d3-4879-f4ad-0f7f45a1a35b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.8367346938775511\n"
          ]
        }
      ],
      "source": [
        "Y = np.array([1, 2]*14)\n",
        "X = np.random.uniform(size=[len(Y), 100])\n",
        "n_iter = 1000\n",
        "ansMat = np.full((len(Y), n_iter), np.nan)\n",
        "for i in range(n_iter):\n",
        "    # Get train/test index\n",
        "    train = np.random.choice(range(len(Y)), size=int(0.5*len(Y)), replace=False, p=None)\n",
        "    if len(np.unique(Y)) == 1:\n",
        "        continue\n",
        "    test = np.array([i for i in range(len(Y)) if i not in train])\n",
        "    # train model\n",
        "    mod = SVC(probability=False)\n",
        "    mod.fit(X=X[train, :], y=Y[train])\n",
        "    # predict and collect answer\n",
        "    ansMat[test, i] = mod.predict(X[test, :])\n",
        "ans = np.nanmean(ansMat, axis=1)\n",
        "fpr, tpr, thresholds = roc_curve(Y, ans, pos_label=1)\n",
        "print(auc(fpr, tpr))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "504cde2c-c5fd-4bc8-8aba-efb044d31198",
      "metadata": {
        "id": "504cde2c-c5fd-4bc8-8aba-efb044d31198"
      },
      "source": [
        "## Your answer"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Possible explaination\n",
        "Computing the area under the curve where both X and Y variables are completely random would not necessarily give a value of 0.5. In fact, the value of the area under the curve would be highly dependent on the distribution of the random points in the plot.\n",
        "\n",
        "If the points are uniformly distributed across the plot, then the area under the curve would be close to 0.5. However, if the points are clustered in certain areas of the plot, then the area under the curve would be different from 0.5.\n",
        "\n",
        "Therefore, in order to accurately compute the area under the curve, it needs to be known more about the distribution. If it's assumed that the distributions are generated randomly according to a probability distribution, then statistical methods can be used to estimate the area under the curve.\n"
      ],
      "metadata": {
        "id": "Es8PAiN-Ingc"
      },
      "id": "Es8PAiN-Ingc"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### More possible explainations\n",
        "There could be several more reasons why the area under the curve (AUC) is frequently significantly higher than 0.5, despite using random data for X and Y.\n",
        "\n",
        "One possibility is overfitting.\n",
        "\n",
        "When using *leave-group-out cross-validation*, the model is trained on a subset of the data and tested on a single observation that was left out. This process is repeated for all observations in the data. If the model is too complex and overfits the data, it may perform well on the training set but poorly on the test set. This can lead to a higher AUC than expected, as the model is essentially memorizing the training set.\n",
        "\n",
        "Another possibility is random chance.\n",
        "\n",
        "Although X and Y are completely random, there is still a chance that the data will create patterns that can be exploited by the model. With only a small number of observations, it is more likely that the model will find these patterns by chance, leading to a higher AUC.\n",
        "\n",
        "Finally, it is possible that the code or implementation of the cross-validation process is incorrect or flawed, leading to incorrect results. It may be useful to double-check the code and ensure that it is correctly implementing leave-group-out cross-validation and calculating AUC."
      ],
      "metadata": {
        "id": "DMI-DhJJcgry"
      },
      "id": "DMI-DhJJcgry"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Countermeasure\n",
        "There are several ways to address overfitting in a code, depending on the specific situation and model being used. There are several ways to address overfitting in a code, including\n",
        "\n",
        "reducing model complexity,\n",
        "\n",
        "regularization,\n",
        "\n",
        "dropout,\n",
        "\n",
        "increasing the amount of training data,\n",
        "\n",
        "early stopping, and\n",
        "\n",
        "using cross-validation.\n",
        "\n",
        "After trying these possibilities, I choose to try changing the leave out leave group\n",
        "out cross validation because it is in the code."
      ],
      "metadata": {
        "id": "gtIHOHhrcrWp"
      },
      "id": "gtIHOHhrcrWp"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Alternative Solution\n",
        "\n",
        "To use **K fold Cross-Validation** in this code instead of leave-group-out cross-validation, to can modify the for loop to perform k-fold cross-validation. Here's an example of how you could modify the code to use 5-fold cross-validation in the following modified R version.\n",
        "\n",
        "The folds variable is created to specify the folds for k-fold cross-validation using the sample() function. Then, the for loop is nested within another loop to iterate through each fold and train the model on the training set before making predictions on the test set. Finally, the results are averaged across all folds to obtain the final AUC."
      ],
      "metadata": {
        "id": "smhsgRKTK6ls"
      },
      "id": "smhsgRKTK6ls"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### R version\n",
        "```R\n",
        "install.packages('e1071')\n",
        "install.packages('pROC')\n",
        "\n",
        "library(e1071)\n",
        "library(pROC)\n",
        "\n",
        "#cross validation instead of leave out\n",
        "Y <- as.factor(rep(c(1,2), times = 14))\n",
        "X <- matrix(runif(length(Y)*100), nrow = length(Y))\n",
        "\n",
        "colnames(X) <- 1:ncol(X)\n",
        "iter <- 1000\n",
        "ansMat <- matrix(NA, length(Y), iter)\n",
        "k <- 7 # number of folds\n",
        "set.seed(123) # set seed for reproducibility\n",
        "folds <- sample(rep(1:k, length.out = length(Y))) # create folds\n",
        "\n",
        "for (i in seq(iter)) {\n",
        "  for (j in 1:k) {\n",
        "    # get training and test indices for current fold\n",
        "    train <- which(folds != j)\n",
        "    test <- which(folds == j)\n",
        "\n",
        "    # train model on current fold\n",
        "    XX <- X[train, ]\n",
        "    YY <- Y[train]\n",
        "    mod <- svm(XX, YY, probability = FALSE)\n",
        "\n",
        "    # make predictions on test set and store results\n",
        "    XXX <- X[test, ]\n",
        "    predVec <- predict(mod, XXX)\n",
        "    RFans <- attr(predVec, 'decision.values')\n",
        "    ansMat[test, i] <- as.numeric(predVec)\n",
        "  }\n",
        "}\n",
        "ans <- rowMeans(ansMat, na.rm = TRUE)\n",
        "r <- roc(Y, ans)$auc\n",
        "print(r)\n",
        "```\n",
        "Area under the curve: 0.6429"
      ],
      "metadata": {
        "id": "u8-X-d-hN3jn"
      },
      "id": "u8-X-d-hN3jn"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Python version gives a lower AUC"
      ],
      "metadata": {
        "id": "JbJ_h7JsIrO1"
      },
      "id": "JbJ_h7JsIrO1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "082f817e-55be-494c-a316-93c4042ed41a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "082f817e-55be-494c-a316-93c4042ed41a",
        "outputId": "1fd19be9-0abf-480f-889c-4121179189bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.3214285714285714\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "Y = np.repeat([1, 2], repeats=14).astype(np.int64)\n",
        "X = np.random.rand(len(Y)*100).reshape((len(Y), 100))\n",
        "\n",
        "iter = 1000\n",
        "ansMat = np.empty((len(Y), iter))\n",
        "k = 5 # number of folds\n",
        "np.random.seed(123) # set seed for reproducibility\n",
        "folds = np.random.choice(k, size=len(Y), replace=True) # create folds\n",
        "\n",
        "for i in range(iter):\n",
        "    for j in range(k):\n",
        "        # get training and test indices for current fold\n",
        "        train = np.where(folds != j)[0]\n",
        "        test = np.where(folds == j)[0]\n",
        "\n",
        "        # train model on current fold\n",
        "        XX = X[train, :]\n",
        "        YY = Y[train]\n",
        "        mod = svm.SVC(probability=False).fit(XX, YY)\n",
        "\n",
        "        # make predictions on test set and store results\n",
        "        XXX = X[test, :]\n",
        "        predVec = mod.predict(XXX)\n",
        "        ansMat[test, i] = predVec.astype(np.float64)\n",
        "\n",
        "ans = np.nanmean(ansMat, axis=1)\n",
        "r = roc_auc_score(Y, ans)\n",
        "print(r)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fcfb3ad1-3f67-403e-9ee4-775b67f76660",
      "metadata": {
        "id": "fcfb3ad1-3f67-403e-9ee4-775b67f76660"
      },
      "source": [
        "## Feedback"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "867962a5-b639-4d39-882c-5a42a68e891c",
      "metadata": {
        "id": "867962a5-b639-4d39-882c-5a42a68e891c"
      },
      "source": [
        "Was this exercise is difficult or not? In either case, briefly describe why."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I feel this task was not difficult because the possiblities were in the code and could be changed in hypermeters, classifiers and gridsearch techniques that could be used to get ideal results.\n",
        "\n",
        "However, the task could be difficult if prediction technique is not a skill that is possessed by someone. A background knowledge in modelling would help in this task."
      ],
      "metadata": {
        "id": "LPtiuz28TTo3"
      },
      "id": "LPtiuz28TTo3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3135c16f-1f49-4d49-bb7c-ee281dcc7f36",
      "metadata": {
        "id": "3135c16f-1f49-4d49-bb7c-ee281dcc7f36"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44e24d48-7fc3-4d06-b1ca-b15e12296322",
      "metadata": {
        "id": "44e24d48-7fc3-4d06-b1ca-b15e12296322"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "stress-multitask",
      "language": "python",
      "name": "stress-multitask"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}